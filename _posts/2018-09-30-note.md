---
layout:     post
title:      "随手笔记"
date:       2018-09-30 12:00:00
author:     "ZhY"
header-img: "img/post-bg-basic.jpg"
header-mask: 0.3
catalog:    true
tags:
    - 强化学习
---




1.打乱数据顺序

shuffled_action_sequences = random.sample(legal_action_sequences, len(legal_action_sequences))


2.根据

不同版本的tf设定不同的api

import distutils.version

use_tf12_api = distutils.version.LooseVersion(tf.VERSION) >= distutils.version.LooseVersion('0.12.0')

if use_tf12_api:
    
	variables_to_restore = [v for v in tf.global_variables() if not v.name.startswith("local")]
    
	init_all_op = tf.global_variables_initializer()

else:
    
	variables_to_restore = [v for v in tf.all_variables() if not v.name.startswith("local")]
   
	init_all_op = tf.initialize_all_variables()


https://zhuanlan.zhihu.com/p/27880839



3.随机

tf.random_normal(shape,mean=0.0,stddev=1.0,dtype=tf.float32,seed=None,name=None)
给出均值和标准差，正态分布随机取值

tf.random_uniform(shape,minval=0,maxval=None,dtype=tf.float32,seed=None,name=None)
返回值的范围默认是0到1的左闭右开区间，即[0，1)。minval为指定最小边界，默认为1。
maxval为指定的最大边界，如果是数据浮点型则默认为1，如果数据为整形则必须指定。


4.根据logits中每个类别的概率采样

tf.multinomial(logits, num_samples, seed=None, name=None) 
logits 大小为[batch，n_class] 
num_samples 表示采样的个数 
seed 随机种子数 
name表示该op的名字

这个函数就是根据logits中每个类别的概率采样，这个概率可以不用归一化后的概率，也就是每个类的概率可以大于1，不需要所有类别概率和为1，我觉得它底层是会自动给我们归一化的，输出结果为[batch,num_samples]大小 
表示在每个batch_size 上采样num_samples个数，他是根据logits中的概率来采样的 

5. ELBO与KL散度和交叉熵
https://blog.csdn.net/yujianmin1990/article/details/71213601
https://blog.csdn.net/colourful_sky/article/details/78534122
https://www.cnblogs.com/yifdu25/p/8278986.html

6.多元正态分布

tf.contrib.distributions.MultivariateNormalDiag

多元正态分布的log probability
tf.contrib.distributions.MultivariateNormalDiag(loc, scale_diag).log_prob(labels)

7.去掉维数为1的维度。
tf.squeeze(x)

# 't' is a tensor of shape [1, 2, 1, 3, 1, 1]
tf.shape(tf.squeeze(t))  # [2, 3]

8.
sess = tf.Session(config=tf_config)
sess.__enter__() 
和
with tf.Session(config=tf_config) as session:
是一样的
