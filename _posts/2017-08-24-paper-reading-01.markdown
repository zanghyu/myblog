---
layout:     post
title:      "A Few Useful Things to Know about Machine Learning 的阅读笔记"
date:       2017-08-24 10:00:00
author:     "ZhY"
header-img: "img/post-bg-basic.jpg"
header-mask: 0.3
catalog:    true
tags:
    - 论文阅读
---

# A Few Useful Things to Know about Machine Learning 的阅读笔记

## 概述

这篇论文主要是cs231n的笔记中的推荐阅读内容，因为据说这篇论文概括性比较强而且值得读，所以就来读一下。论文有中文翻译版本，译名是《机器学习那些事》，译者刘知远。

这论文简要介绍了机器学习应用时的一些"black art"还有一些关键点，介绍这些的同时又简单说了一下这些关键点中有哪些坑。用好这些"black art"可以提高一些项目的开发效率，得到更好的效果。

这部分简要介绍了下机器学习的发展史以及现在机器学习的应用领域：网页搜索、垃圾邮件分类、推荐系统、广告、资信评分、诈骗侦测、股票交易、药物制作等领域。

后面提到了12个"民间知识"(folk knowledge)。（都是以分类作为例子）

## 民间知识

### 学习 = 表示 + 评价 + 优化

learning = representation + evaluation + optimization

为学习器选择一种表示就相当于（be tantamount to)选择一个它可能学到的特定的分类器的集合（这个集合就是所谓的假设空间——hypothesis space)；评价函数（目标函数、打分函数）显示学习器的好坏程度；优化是通过某种搜索方法在假设空间中找到评价函数得分最高的那个分类器。

下面两幅图举了一些例子，分别是学习算法中的这三个部分

![](/img/in-post/paper-reading/paper-reading-01-01.jpg)

![](/img/in-post/paper-reading/paper-reading-01-02.jpg)

### 泛化能力很重要

由于训练集永远不会包含所有情况，所以机器学习的根本目的就是为了泛化，通过已知的去预测（猜测）未知的东西。

由于在乎的是泛化能力，因此在训练(train)过程中千万不要碰测试(test)数据。在得到一定量的数据之后，首先要做的应该是分出来测试数据和训练数据。由于机器学习中需要调节很多超参数（比如cs231n的knn实验中的k的选择和距离算法的选择),这些超参数有时候需要通过测试结果来进行调节，通过结果的好坏来选取更加有效的超参数。因此又需要把训练集的一部分拿出来当做验证集(validation set)，通过剩下的大部分进行训练，然后在验证集上验证结果的好坏，再去调节超参数，重复进行，得到最终结果。如果数据过少，可以采用交叉验证的方式进行。尽量避免交叉验证，因为耗费过多计算资源，一般直接按照训练集的50%-90%的比例分训练集和验证集。如果超参数特别多，可能要用更大的验证集。如果验证集不够，最好选用交叉验证。

### 仅仅有数据还不够

每个学习器都必须包含一些数据之外的知识或假设，才能够将数据泛化。这个概念也被形式化成了“没有免费午餐”(no free lunch)定理。关于这个定理也有一篇[相关的博文][1]解释。机器学习其实就是归纳的过程，通过将少量的输入知识转化为大量的输出知识。

真正的机器学习并不是从假设集合中一个一个挑，而是有一些先验知识帮助我们更好的筛选。先验知识就是，针对不同领域，已经拥有的可以使机器学习更容易做出选择，选到好的知识。比如如果拥有概率依赖(probabilistic dependencies)的知识，那么也许图模型能更好的表达；如果拥有每个类别的先决条件的知识，那"if...then..."可以更好表达。

这里的一段话我觉得讲的特别好：

***In retrospect, the need for knowledge in learning should not be surprising. Machine learning is not magic; it can’t get something from nothing. What it does is get more from less. Programming, like all engineering, is a lot of work:  we have to build everything from scratch. Learning is more like farming, which lets nature do most of the work. Farmers combine seeds with nutrients to grow crops. Learners combine knowledge with data to grow programs.***

### 过拟合有很多面孔

过拟合的一种表现形式是讲泛化误差(generallization error)分解为偏差(bias)和方差(variance)，偏差是度量了学习器倾向于一直学习相同错误的程度，方差度量了学习器倾向于忽略真实信号、学习随机事物的程度。

高偏差代表距离正确的越远，高方差代表学习的结果太过分散。比如决策树相比于线性分类器来说偏差较低但方差较高；贪心搜索比[柱搜索(beam search)][2]偏差高而方差低，因为柱搜索会尝试更多假设。

在机器学习领域还有一种现象很常见：一个强错误假设比那些弱正确假设更好，因为后者需要更多的数据才能避免过拟合。

避免过拟合的几种方式：

**交叉验证([不能做太多的参数选择][3]——ng的一篇论文有解释)**

**[对评价函数增加正则项][4]**

**进行显著性检验(如卡方测试)**

我们需要注意的是过拟合并不一定是噪音产生的，如果要用显著性检验去避免过拟合，那么最好控制错误接受的非零假设的比率，这样才能避免出现欠拟合。

### 直觉不适用于高维空间

机器学习中还有一个问题就是维度灾难：许多在低位空间表现很好的算法，当输入是高维度的时候，就变得计算不可行。**样例维度**的增长就是**特征数目**的增长,随着这种增长，

1)训练数据会不够用

2)过多的特征只有少量才起重要作用。而且过多特征会带来大量噪声

3)数据在高维度的时候会变的很近，不易于分类

比如针对于一维中一个点来说，它的临近点只有左右两个，而二维的一个点的临近点就有上下左右4个。随着维度的升高，它的近邻会越来越多，最后会变成随机的。

这里讲了个很有趣的现象，说我们三维空间的直观感觉和高维空间是不一样的，高维空间的大部分质量都是在壳上。打个比方就是，三维空间的橘子，质量在瓤上，而高维空间的质量在皮上。 比如三个分别在立方体三个面的点，在更高维空间他们是近邻的，然而他们与自己所在的立方体某个面的距离小于他们之间最近邻的距离。在这种情况下，如果超立方体内接超球面，会发现超立方体大部分质量都在超球面外（不是太懂为什么）。因为机器学习需要用一种类型的形状近似另一种，所以维度升高是个坏消息。

幸运的是，有一个叫做“分均匀性祝福”的特点可以起到一定的帮助。大概说的是，即使橘子的质量都在皮上也不是均匀的分布在皮上，还是集中在一些区域内的，所以可以隐式的利用这个空间或者降维。

### 理论保证和看上去的不一样

这里提到了两个保证：边界保证和渐进保证

边界(bound)保证：边界是给定一个足够大的训练集，会告诉你在很大概率上学习器返回一个成功泛化的假设（或者无法找到）。告诉我们，如果在这个假设空间包含真实分类器，那么随着训练数据规模的增长，输出坏分类器的概率会降低；如果缩小假设空间，边界会改善，但是空间包含真实分类器的几率也变低了。

渐进(asymptotic)保证：给定无穷数据，学习器将保证输出正确的分类器。

需要注意的是机器学习中的理论保证就是为了理解，不会再实际运用中起决策作用，顶多就是在设计算法的时候给些提示。

### 特征工程是关键

通常原始数据不能直接使用拿来学习，需要从中构建特征，就像kaggle的入门竞赛titanic那样，只有合适的特征，才能训练处更好的模型。真正的项目中有很多时间都在进行数据收集、整合、清理、预处理以及特征设计了。特征工程是领域相关的，而学习器则是通用的。虽然现在经常采用通过信息增益等方式自动化选择特征，但是这种方式耗时且易过拟合，总体来说还是要人工参与进去。

### 更多的数据胜过更聪明的算法

想要更好的效果一般有两种选择：设计更好的学习算法，或者收集更多数据。虽然事实上在企业中如果项目很难收集更多的数据时候，我们只能完善算法，但是从实用角度来说，最快捷的方法还是收集更多数据。

这也带来了可扩展性的问题，机器学习面临了三个资源有限的问题：时间、内存和训练数据。更多的数据意味着可以学习更复杂的分类器，但是却也需要更多时间。

有一条规则是首先尝试最简单的学习器。更复杂的学习器往往需要调节更多参数，而且内部机制更不透明。

说到底，最大瓶颈在于如何节约人力，更加便捷的得到更有效的结论。

### 要学习很多模型，而不仅仅是一个

模型集成，将多个学习器结合，往往结果会更好。现在一般采用bagging的方法，通过重采样随机产生若干训练集，在每个集合训练分类器，用投票方式合并结果。除此之外海域拥有boosting,stacking等方法。

这里提到模型集成和贝叶斯模型平均的不同。模型集成改变了假设空间，BMA知识对空间的假设赋予不同权重；两者的权重也不同，前者很平均，后者波动很大。

### 简单并不意味着准确

奥坎姆剃刀原则：若无必要，勿增实体

这部分主要的结论就是先选择简单假设，然后在慢慢修正，而不要一开始就从复杂的入手。

### 可表示并不意味着可学习

一个函数可以被表示出来，不见得就能被学习。这个意思就是说，我们给定了数据、时间和内存，用标准的学习器来学习，但是只能学到所有可能函数中的一部分，并不能学到所有的函数。因此，有的函数它能够写成某种形式，但是，我们也可能没办法求到它。因此，要多试一些学习器。

### 相关并不意味着因果

我们只是发现观测变量之间的相关性，但我们还希望从观测数据发现因果信息。另一方面，相关性是因果关系的标志，我们可以将其作为进一步考察的指南（例如试图理解因果链可能是什么样）

## 总结

其实这篇论文在我的理解里是指导进行机器学习项目的一个概述，说明了又哪些注意点哪些坑以及如何规避这些坑。但是有小部分，比如：高维空间的质量问题，还不太理解。不过还是很有意思的一篇论文，感觉花了几个小时时间看还是挺值得的。

---
[1]:http://blog.csdn.net/thither_shore/article/details/52324776
[2]:http://blog.csdn.net/nwpulei/article/details/8133851
[3]:http://xueshu.baidu.com/s?wd=paperuri:(776f5c0bdab283e6eda1730ca2292db4)&filter=sc_long_sign&sc_ks_para=q%3DPreventing+%22Overfitting%22+of+Cross-Validation+Data&tn=SE_baiduxueshu_c1gjeupa&ie=utf-8&sc_us=6500644644533683566
[4]:https://www.zhihu.com/question/20700829


