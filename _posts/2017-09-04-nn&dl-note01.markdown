---
layout:     post
title:      "deeplearning.ai学习笔记01"
subtitle:   "第一周"
date:       2017-09-04 21:00:00
author:     "ZhY"
header-img: "img/post-bg-basic.jpg"
header-mask: 0.3
catalog:    true
tags:
    - 学习笔记
---

#神经网络模型

针对于房价预测来说，预科模型可以表示为如下形式：

![](/img/in-post/nn&dl/note01-01.png)

这是四个输入的神经网络，通过输入这四个特征，来预测房价。中间竖着的三个圆圈在神经网络中被称为隐层（隐藏单元）。

# 激活函数的作用

是为了增加神经网络模型的非线性。否则没有激活函数的每层都相当于矩阵相乘。就算叠加了若干层之后，无非还是个矩阵相乘罢了。所以没有非线性结构的话，根本就算不上什么神经网络。

# 为什么通常Relu比sigmoid和tanh强，有什么不同？

![](/img/in-post/nn&dl/note01-05.png)

从左到右依次为：tanh sigmoid relu

主要是因为它们gradient特性不同。sigmoid和tanh的gradient在饱和区域非常平缓，接近于0，很容易造成vanishing gradient的问题，减缓收敛速度。vanishing gradient在网络层数多的时候尤其明显，是加深网络结构的主要障碍之一。相反，Relu的gradient大多数情况下是常数，有助于解决深层网络的收敛问题。Relu的另一个优势是在生物上的合理性，它是单边的，相比sigmoid和tanh，更符合生物神经元的特征。而提出sigmoid和tanh，主要是因为它们全程可导。还有表达区间问题，sigmoid和tanh区间是0到1，或着-1到1，在表达上，尤其是输出层的表达上有优势。

# 监督学习中的神经网络

![](/img/in-post/nn&dl/note01-02.png)

房价预测和广告一般都用普通的神经网络进行计算，而图像领域（图像分类、无人驾驶）经常使用CNN，对于时间序列（比如音频、视频、语言）数据经常使用RNN。

![]( note01-03.png)

# 深度学习的发展

![]( note01-04.png)

当数据量较小时，可能其他的一些机器学习算法（比如SVM等）泛化能力较强，结果更好；但是数据量很大的时候，神经网络的性能会明显优于其他算法。

现在来说，想要更好的效果可以从三个方面努力：数据量的提升、计算能力的加强、算法的改进。计算能力的加强主要是CPU和GPU的发展，而算法的改进大多都是为了让神经网络计算更快。



